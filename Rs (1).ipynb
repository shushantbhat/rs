{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Crop Disease & Yield Prediction system"
      ],
      "metadata": {
        "id": "9cCDJVc7k53D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWxqKDaSkxqm",
        "outputId": "381dfc42-328d-42e8-f07a-4f3074d37d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disease Prediction: 0.4347 (0:Healthy,1:Diseased)\n",
            "Yield Prediction: 49.63 units\n",
            "Recommendation: Low yield! Improve irrigation.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- CNN: Crop Disease Detection ---\n",
        "X_img, y_img = np.random.rand(100,64,64,3), np.random.randint(2,size=100)\n",
        "cnn = Sequential([\n",
        "    Conv2D(32,(3,3),activation='relu',input_shape=(64,64,3)),\n",
        "    MaxPooling2D(2,2), Flatten(),\n",
        "    Dense(128,activation='relu'),\n",
        "    Dense(1,activation='sigmoid')\n",
        "])\n",
        "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "cnn.fit(X_img,y_img,epochs=3,batch_size=10,verbose=0)\n",
        "\n",
        "# --- Random Forest: Yield Prediction ---\n",
        "X, y = np.random.rand(100,3), np.random.rand(100)*100\n",
        "Xtr, Xte, ytr, yte = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "rf = RandomForestRegressor(n_estimators=100,random_state=42).fit(Xtr,ytr)\n",
        "\n",
        "# --- Recommendation ---\n",
        "def recommend(d_pred,y_pred):\n",
        "    if d_pred>=0.5: return \"Disease detected! Apply pesticide.\"\n",
        "    if y_pred<50: return \"Low yield! Improve irrigation.\"\n",
        "    return \"Crop healthy, yield optimal.\"\n",
        "\n",
        "# --- Test with Simulated Inputs ---\n",
        "test_img = np.random.rand(1,64,64,3)\n",
        "d_pred = cnn.predict(test_img,verbose=0)[0][0]\n",
        "y_pred = rf.predict([[0.8,0.6,0.7]])[0]\n",
        "print(f\"Disease Prediction: {d_pred:.4f} (0:Healthy,1:Diseased)\")\n",
        "print(f\"Yield Prediction: {y_pred:.2f} units\")\n",
        "print(\"Recommendation:\", recommend(d_pred,y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "content-based movie recommendation system"
      ],
      "metadata": {
        "id": "fTBmVhMfk_cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Data\n",
        "movies = pd.DataFrame({\n",
        " 'title':['The Shawshank Redemption','The Godfather','The Dark Knight','Pulp Fiction','The Lord of the Rings: The Return of the King'],\n",
        " 'genres':['Drama','Crime, Drama','Action, Crime, Drama','Crime, Drama','Action, Adventure, Fantasy'],\n",
        " 'desc':['Two imprisoned men bond over years.','Patriarch transfers crime dynasty.','Joker wreaks havoc on Gotham.','Mob hitmen tales of violence.','Gandalf and Aragorn fight Sauron.']\n",
        "})\n",
        "movies['content']=movies['genres']+' '+movies['desc']\n",
        "\n",
        "# TF-IDF + Similarity\n",
        "tfidf=TfidfVectorizer(stop_words='english')\n",
        "sim=linear_kernel(tfidf.fit_transform(movies['content']),tfidf.fit_transform(movies['content']))\n",
        "\n",
        "def recommend(title):\n",
        "    i=movies[movies['title']==title].index[0]\n",
        "    scores = list(enumerate(sim[i]))\n",
        "    # Sort by similarity, skip the movie itself (index 0)\n",
        "    top = sorted(scores, key=lambda x: x[1], reverse=True)[1:4]\n",
        "    return movies['title'][[j[0] for j in top]]\n",
        "    # for j in top:\n",
        "    # print(movies['title'][j[0]])\n",
        "# Output\n",
        "print(\"Recommendations for 'The Godfather':\\n\", recommend('The Godfather'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9xR0TPwlCeF",
        "outputId": "5343cd5a-33f2-4f87-f5cc-5e6acb4f2190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for 'The Godfather':\n",
            " 3                Pulp Fiction\n",
            "2             The Dark Knight\n",
            "0    The Shawshank Redemption\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hybrid movie recommendation system"
      ],
      "metadata": {
        "id": "0aKBKbQvlE6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, pairwise_distances\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Data\n",
        "movies = pd.DataFrame({\n",
        " 'title':['The Shawshank Redemption','The Godfather','The Dark Knight','Pulp Fiction','The Lord of the Rings: The Return of the King'],\n",
        " 'genres':['Drama','Crime, Drama','Action, Crime, Drama','Crime, Drama','Action, Adventure, Fantasy'],\n",
        " 'desc':['Two imprisoned men bond.','Patriarch transfers crime dynasty.','Joker wreaks havoc.','Mob hitmen tales.','Gandalf vs Sauron.']\n",
        "})\n",
        "movies['content']=movies['genres']+' '+movies['desc']\n",
        "\n",
        "ratings=pd.DataFrame({\n",
        " 'user_id':[1,1,1,2,2,3,3],\n",
        " 'title':['The Shawshank Redemption','The Godfather','The Dark Knight','The Dark Knight','Pulp Fiction','The Shawshank Redemption','Pulp Fiction'],\n",
        " 'rating':[5,4,5,4,5,5,4]\n",
        "})\n",
        "\n",
        "# Models\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "cos_sim = linear_kernel(tfidf.fit_transform(movies['content']))\n",
        "mat = csr_matrix(ratings.pivot(index='user_id', columns='title', values='rating').fillna(0).values)\n",
        "latent = TruncatedSVD(2).fit_transform(mat)\n",
        "\n",
        "# Functions\n",
        "def content_rec(title):\n",
        "    idx=movies[movies['title']==title].index[0]\n",
        "    sim = sorted(list(enumerate(cos_sim[idx])), key=lambda x:x[1], reverse=True)[1:4]\n",
        "    return [movies['title'][i[0]] for i in sim]\n",
        "\n",
        "def collab_rec(uid):\n",
        "    i = ratings['user_id'].unique().tolist().index(uid)\n",
        "    sim = pairwise_distances(latent[i].reshape(1,-1), latent, metric='cosine')[0].argsort()[:3]\n",
        "    rec = []\n",
        "    for j in sim:\n",
        "      similar_user_id = ratings['user_id'].unique()[j]       # get actual user ID (not just position)\n",
        "      user_movies = ratings[ratings['user_id'] == similar_user_id]['title']  # movies that user rated\n",
        "      rec.extend(user_movies)\n",
        "      return list(set(rec))\n",
        "\n",
        "def hybrid(uid, title):\n",
        "    return list(set(content_rec(title) + collab_rec(uid)))\n",
        "\n",
        "# Output\n",
        "print(\"Hybrid Recommendations:\", hybrid(1, 'The Godfather'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF2_Mgo4lIK2",
        "outputId": "7467964f-0bc1-4e93-cf00-f36ad75b144a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hybrid Recommendations: ['The Shawshank Redemption', 'Pulp Fiction', 'The Dark Knight', 'The Godfather']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "r Breast Cancer Prediction code"
      ],
      "metadata": {
        "id": "t_xTujKolY59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Data\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model\n",
        "m = RandomForestClassifier(100, random_state=42).fit(Xtr, ytr)\n",
        "yp = m.predict(Xte)\n",
        "\n",
        "# Results\n",
        "print(\"Accuracy:\", accuracy_score(yte, yp))\n",
        "print(\"\\nReport:\\n\", classification_report(yte, yp))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(yte, yp))\n",
        "\n",
        "# Recommendation\n",
        "def advise(f):\n",
        "    return (\"⚠️ Malignant! Consult doctor.\" if m.predict([f])[0]==0\n",
        "            else \"✅ Benign. Routine checkup.\")\n",
        "\n",
        "print(\"\\nRecommendation:\", advise(Xte[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbahzuHElX_E",
        "outputId": "7f90acaf-aa57-4b08-f873-e572dfd46b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n",
            "\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "Confusion Matrix:\n",
            " [[40  3]\n",
            " [ 1 70]]\n",
            "\n",
            "Recommendation: ✅ Benign. Routine checkup.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# === 1. Load and preprocess ===\n",
        "df = pd.read_csv('/content/RS-A5_amazon_products_sales_data_cleaned.csv')\n",
        "df['product_rating'] = df['product_rating'].fillna(df['product_rating'].mean())\n",
        "df = df.sample(5000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Add dummy user and product IDs\n",
        "df['user_id'] = np.random.randint(0, 500, len(df))  # 500 users for better overlap\n",
        "df['product_id'] = df.index\n",
        "\n",
        "# === 2. Create user-item matrix ===\n",
        "pivot = df.pivot_table(index='user_id', columns='product_id', values='product_rating').fillna(0)\n",
        "\n",
        "# === 3. Apply SVD ===\n",
        "svd = TruncatedSVD(n_components=50, random_state=42)\n",
        "latent_matrix = svd.fit_transform(pivot)\n",
        "reconstructed = np.dot(latent_matrix, svd.components_)\n",
        "\n",
        "# === 4. Recommend top 5 items for a random user ===\n",
        "# NOTE: `train` was undefined — we should pick from pivot.index instead\n",
        "user_id = np.random.choice(pivot.index)\n",
        "user_idx = pivot.index.get_loc(user_id)\n",
        "\n",
        "pred_ratings = reconstructed[user_idx]\n",
        "\n",
        "# Find items already rated by the user\n",
        "rated_items = pivot.columns[pivot.iloc[user_idx] > 0]\n",
        "\n",
        "# Exclude already-rated items from recommendations\n",
        "pred_ratings = {pid: score for pid, score in zip(pivot.columns, pred_ratings) if pid not in rated_items}\n",
        "\n",
        "# Sort predicted ratings\n",
        "top5 = sorted(pred_ratings.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "# === 5. Display results ===\n",
        "print(f\"\\nTop 5 Recommendations for user ID {user_id} :\\n\")\n",
        "for i,_ in top5:\n",
        "    print(i, \"--->\", df.loc[i, 'product_title'])"
      ],
      "metadata": {
        "id": "cLJiX0OF0BtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "df1 = pd.read_csv('/content/RS-A2_A3_movie.csv')\n",
        "df2 = pd.read_csv('/content/RS-A2_A3_tag.csv')\n",
        "\n",
        "movies = df1.merge(df2, on='movieId').fillna('')\n",
        "movies['context'] = movies['genres'] + \" \" + movies['tag']\n",
        "\n",
        "# IMPORTANT: reset index after sampling\n",
        "movies = movies.sample(10000).reset_index(drop=True)\n",
        "print(movies.head())\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "mat = tfidf.fit_transform(movies['context'])\n",
        "sim = linear_kernel(mat, mat)\n",
        "\n",
        "def reco(id):\n",
        "    # row index in the sampled dataset\n",
        "    i = movies[movies['movieId'] == id].index\n",
        "    i = i[0]\n",
        "    score = list(enumerate(sim[i]))\n",
        "    top = sorted(score, key=lambda x: x[1], reverse=True)[1:4]\n",
        "    for j, _ in top:\n",
        "        print(movies.loc[j, 'title'])\n",
        "\n",
        "\n",
        "="
      ],
      "metadata": {
        "id": "HB6yo3LTp4xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, pairwise_distances\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# ✅ Load datasets\n",
        "df1 = pd.read_csv('/content/RS-A2_A3_movie.csv')\n",
        "df2 = pd.read_csv('/content/RS-A2_A3_tag.csv')\n",
        "df3 = pd.read_csv('/content/RS-A2_A3_Filtered_Ratings.csv')\n",
        "\n",
        "# ✅ Merge (movie + tags)\n",
        "movies = df1.merge(df2, on='movieId', how='left').fillna('')\n",
        "\n",
        "# ✅ SAMPLE **10,000 rows**\n",
        "movies = movies.sample(10000).reset_index(drop=True)\n",
        "\n",
        "# ✅ Create content column\n",
        "movies['content'] = movies['genres'] + ' ' + movies['tag']\n",
        "\n",
        "# ✅ Content-based model\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movies['content'])\n",
        "\n",
        "# ✅ Cosine similarity on 10K movies\n",
        "cos_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# ✅ Merge ratings with movie titles (using sampled movie list)\n",
        "ratings = df3.merge(movies[['movieId', 'title']], on='movieId', how='inner')\n",
        "\n",
        "# ✅ User-item matrix for collaborative filtering\n",
        "pivot = ratings.pivot_table(\n",
        "    index='userId',\n",
        "    columns='title',\n",
        "    values='rating'\n",
        ").fillna(0)\n",
        "\n",
        "mat = csr_matrix(pivot.values)\n",
        "\n",
        "# ✅ SVD (use 20 components for 10k data)\n",
        "latent = TruncatedSVD(n_components=20, random_state=42).fit_transform(mat)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# ✅ FUNCTIONS\n",
        "# -------------------------------------------------------\n",
        "\n",
        "def content_rec(title, top_n=5):\n",
        "    \"\"\"Content-based recommendation\"\"\"\n",
        "    if title not in movies['title'].values:\n",
        "        return [\"Title not in 10k sampled movies\"]\n",
        "\n",
        "    idx = movies[movies['title'] == title].index[0]\n",
        "\n",
        "    scores = list(enumerate(cos_sim[idx]))\n",
        "    scores_sorted = sorted(scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
        "\n",
        "    return [movies.iloc[i[0]]['title'] for i in scores_sorted]\n",
        "\n",
        "\n",
        "def collab_rec(uid, top_n=5):\n",
        "    \"\"\"Collaborative filtering recommendation\"\"\"\n",
        "    if uid not in pivot.index:\n",
        "        return [\"User ID not found in rating dataset\"]\n",
        "\n",
        "    user_idx = list(pivot.index).index(uid)\n",
        "\n",
        "    distances = pairwise_distances(\n",
        "        latent[user_idx].reshape(1, -1),\n",
        "        latent,\n",
        "        metric='cosine'\n",
        "    )[0]\n",
        "\n",
        "    similar_users = distances.argsort()[1:top_n+1]\n",
        "\n",
        "    rec_movies = []\n",
        "    for su in similar_users:\n",
        "        real_uid = pivot.index[su]\n",
        "        user_movies = ratings[ratings['userId'] == real_uid]['title'].tolist()\n",
        "        rec_movies.extend(user_movies)\n",
        "\n",
        "    return list(set(rec_movies))\n",
        "\n",
        "\n",
        "def hybrid(uid, title):\n",
        "    \"\"\"Hybrid recommendation = content + collab\"\"\"\n",
        "    c = content_rec(title)\n",
        "    k = collab_rec(uid)\n",
        "    return list(set(c + k))\n",
        "\n",
        "\n",
        "# ✅ SAMPLE OUTPUT\n",
        "print(\"✅ Hybrid Recommendations:\", hybrid(1, movies.loc[0, 'title']))\n"
      ],
      "metadata": {
        "id": "PpTA7RwcgOmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, pairwise_distances\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# ✅ Load datasets\n",
        "df1 = pd.read_csv('/content/RS-A2_A3_movie.csv')\n",
        "df2 = pd.read_csv('/content/RS-A2_A3_tag.csv')\n",
        "df3 = pd.read_csv('/content/RS-A2_A3_Filtered_Ratings.csv')\n",
        "\n",
        "# ✅ Merge movie + tags\n",
        "movies = df1.merge(df2, on='movieId', how='left').fillna('')\n",
        "\n",
        "# ✅ Sample 10k movies\n",
        "movies = movies.sample(10000).reset_index(drop=True)\n",
        "\n",
        "# ✅ Prepare content text\n",
        "movies['content'] = movies['genres'] + ' ' + movies['tag']\n",
        "\n",
        "# ✅ Content-based model\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "cos_sim = linear_kernel(tfidf.fit_transform(movies['content']))\n",
        "\n",
        "# ✅ Merge ratings only for sampled movies\n",
        "ratings = df3.merge(movies[['movieId','title']], on='movieId', how='inner')\n",
        "\n",
        "# ✅ Collaborative model pivot\n",
        "pivot = ratings.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "latent = TruncatedSVD(20, random_state=42).fit_transform(csr_matrix(pivot.values))\n",
        "\n",
        "\n",
        "\n",
        "# ✅ ✅ ✅ FUNCTIONS USING movieId\n",
        "# -------------------------------------------------------\n",
        "\n",
        "def content_rec(movie_id, top_n=5):\n",
        "    \"\"\"Content-based recommendation using movieId\"\"\"\n",
        "    if movie_id not in movies['movieId'].values:\n",
        "        return [\"Movie ID not in sampled 10k dataset\"]\n",
        "\n",
        "    idx = movies.index[movies['movieId'] == movie_id][0]\n",
        "\n",
        "    sims = list(enumerate(cos_sim[idx]))\n",
        "    sims_sorted = sorted(sims, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
        "\n",
        "    rec_ids = [movies.iloc[i[0]]['movieId'] for i in sims_sorted]\n",
        "    return rec_ids\n",
        "\n",
        "\n",
        "\n",
        "def collab_rec(uid, top_n=5):\n",
        "    \"\"\"Collaborative filtering recommendation using userId\"\"\"\n",
        "    if uid not in pivot.index:\n",
        "        return [\"User ID not found\"]\n",
        "\n",
        "    user_idx = list(pivot.index).index(uid)\n",
        "\n",
        "    distances = pairwise_distances(\n",
        "        latent[user_idx].reshape(1, -1),\n",
        "        latent,\n",
        "        metric='cosine'\n",
        "    )[0]\n",
        "\n",
        "    similar_users = distances.argsort()[1:top_n+1]\n",
        "\n",
        "    rec_ids = []\n",
        "    for u in similar_users:\n",
        "        real_uid = pivot.index[u]\n",
        "        watched = ratings[ratings['userId'] == real_uid]['movieId'].tolist()\n",
        "        rec_ids.extend(watched)\n",
        "\n",
        "    return list(set(rec_ids))\n",
        "\n",
        "\n",
        "\n",
        "def hybrid(uid, movie_id):\n",
        "    \"\"\"Hybrid = content + collaborative\"\"\"\n",
        "    c = content_rec(movie_id)\n",
        "    k = collab_rec(uid)\n",
        "    return list(set(c + k))\n",
        "\n",
        "\n",
        "\n",
        "# ✅ SAMPLE TEST (using movieId)\n",
        "sample_movie_id = movies.loc[0, 'movieId']\n",
        "print(\"Movie ID:\", sample_movie_id)\n",
        "print(\"✅ Hybrid Recommendations:\", hybrid(1, sample_movie_id))\n"
      ],
      "metadata": {
        "id": "rJiDdUzNgxNx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}